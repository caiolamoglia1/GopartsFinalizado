import pandas as pd
import os
import chardet  # Importa√ß√£o direta do chardet para detec√ß√£o autom√°tica (n√£o manual)

print("‚úÖ Chardet dispon√≠vel - usando detec√ß√£o autom√°tica de encoding")

# Fun√ß√£o para detectar encoding do arquivo
def detectar_encoding(caminho_arquivo):
    """
    Detecta o encoding de um arquivo usando chardet (detec√ß√£o autom√°tica)
    """
    print("üîç Usando chardet para detec√ß√£o autom√°tica...")
    with open(caminho_arquivo, 'rb') as file:
        raw_data = file.read(10000)  # L√™ os primeiros 10KB
        resultado = chardet.detect(raw_data)
        encoding_detectado = resultado['encoding']
        confianca = resultado['confidence']
        print(f"   üìä Encoding detectado: {encoding_detectado} (confian√ßa: {confianca:.2%})")
        return encoding_detectado

# Define o diret√≥rio base do projeto
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
INPUT_FILE = os.path.join(BASE_DIR, 'data', 'input', 'produtos_bagun√ßados_latin1.csv')
OUTPUT_FILE = os.path.join(BASE_DIR, 'data', 'output', 'produtos_limpos_utf8.csv')

# Detecta o encoding usando chardet (automaticamente)
encoding_detectado = detectar_encoding(INPUT_FILE)
# Prioriza o encoding detectado, mas mant√©m outros como fallback
encodings_para_testar = [encoding_detectado, 'utf-8', 'latin1', 'iso-8859-1']  

for encoding in encodings_para_testar:
    try:
        print(f"üîç Tentando encoding: {encoding}")
        # L√™ linha por linha para tratar inconsist√™ncias manualmente
        linhas = []
        with open(INPUT_FILE, 'r', encoding=encoding) as file:
            for i, linha in enumerate(file):
                if i == 0:  # Header
                    linhas.append(linha.strip())
                    continue
                
                # Divide a linha em campos
                campos = linha.strip().split(',')
                
                # Se h√° mais de 4 campos, junta os extras no campo 'estoque'
                if len(campos) > 4:
                    # Mant√©m nome_produto, codigo, preco
                    nome_produto = campos[0]
                    codigo = campos[1] 
                    preco = campos[2]
                    # Junta todos os campos restantes como estoque (pega o √∫ltimo v√°lido)
                    estoque = campos[3] if campos[3].strip() else (campos[4] if len(campos) > 4 and campos[4].strip() else '')
                    
                    linha_corrigida = f"{nome_produto},{codigo},{preco},{estoque}"
                    linhas.append(linha_corrigida)
                else:
                    linhas.append(linha.strip())
        
        # Agora cria o DataFrame a partir das linhas corrigidas
        import io
        csv_corrigido = '\n'.join(linhas)
        df = pd.read_csv(io.StringIO(csv_corrigido))
        
        print(f"‚úÖ Arquivo carregado com encoding: {encoding}")
        print(f"üìä Exemplo de nome: {df['nome_produto'].iloc[1]}")
        break
        
    except (UnicodeDecodeError, FileNotFoundError) as e:
        print(f"‚ùå Erro com {encoding}: {e}")
        continue
else:
    print("‚ùå Nenhum encoding funcionou!")
    exit()

print(f"\nüìä Dados ANTES da limpeza ({len(df)} produtos):")
print("Estrutura das colunas:", list(df.columns))
print(df.to_string())

def normalizar_preco(valor) -> float:
    """Normaliza valores de pre√ßo em diferentes formatos"""
    # Verifica se o valor √© nulo, NaN ou vazio
    if valor is None or pd.isna(valor) or valor == '':
        return 0.0
    
    s = str(valor).strip()
    # Verifica valores inv√°lidos (incluindo representa√ß√µes de NaN)
    if not s or s.lower() in {"nan", "none", "null", "n/a", "na"}:
        return 0.0
    
    # Remove R$ e espa√ßos
    s = s.replace("R$", "").replace(" ", "")
    
    # Corrige formato brasileiro: 1.250,00 -> 1250.00
    if "," in s and "." in s:
        s = s.replace(".", "").replace(",", ".")
        print(f"  üîÑ Formato brasileiro: {valor} ‚Üí {s}")
    elif "," in s:
        s = s.replace(",", ".")
        print(f"  üîÑ V√≠rgula decimal: {valor} ‚Üí {s}")
    
    try:
        return float(s)
    except ValueError:
        print(f"  ‚ö†Ô∏è Erro ao converter: {valor}")
        return 0.0

print("\nüí∞ Normalizando pre√ßos...")
# Conta quantos NaN temos antes
nan_count_preco = df['preco'].isna().sum()
if nan_count_preco > 0:
    print(f"  üìä Encontrados {nan_count_preco} valores NaN em pre√ßos - convertendo para 0.0")
    
df['preco'] = df['preco'].apply(normalizar_preco)

print("\nüì¶ Limpando estoque...")
# Conta quantos NaN temos antes
nan_count_estoque = df['estoque'].isna().sum()
if nan_count_estoque > 0:
    print(f"  üìä Encontrados {nan_count_estoque} valores NaN em estoque - convertendo para 0")

# Valores inv√°lidos para o estoque (incluindo todas as representa√ß√µes de NaN)
valores_invalidos = ['None', 'n/a', 'N/A', 'nan', 'NaN', 'null', 'NULL', 'na', 'NA', -1, '-1', '', ' ']
df['estoque'] = df['estoque'].replace(valores_invalidos, 0)
# Preenche NaN com 0 (valores vazios no CSV)  
df['estoque'] = df['estoque'].fillna(0)
# Converte para num√©rico, colocando 0 para valores que n√£o conseguir converter
df['estoque'] = pd.to_numeric(df['estoque'], errors='coerce').fillna(0).astype(int)

print("\nüè∑Ô∏è Limpando nomes dos produtos...")
df['nome_produto'] = df['nome_produto'].str.strip()

# Salva com encoding UTF-8 para preservar acentos
df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')

print("\n" + "=" * 60)
print(f"\nüîç Dados DEPOIS da limpeza ({len(df)} produtos):")
print(df.to_string())
print(f"\n‚úÖ Arquivo salvo como: {OUTPUT_FILE}")
print("\n" + "=" * 60)

